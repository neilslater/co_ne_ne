CoNeNe TODOs:

    YARD docs

    Add concept of training set

    Bulk training

    Use SIMD for weight updates

    Layer.clear_input (?)


CoNeNe DONE:

    Lock first layer in network, to prevent adding earlier layers

    Factor training cycle et al to struct_mlp_network

    Clone a network

    Fill starting NArrays with 0.0

    Init network from first layer

    Init network from array of layers (in Ruby)

    Marshalling, for layers and network

    Learning rate and momentum for network
